### 📝 회의 내용

https://chromewebstore.google.com/detail/copy-to-notion-clip-anyth/jbeooomlnkgbokicnpcabkpnacabjnbm?hl=ko

→ 확장 프로그램

템플릿 O/X여부 정하기

템플릿 사용 O

- **입력 → 마스킹 → 프롬프트 생성**

템플릿에 들어갈 내용

- 프롬프트 사용 목적
- 사용자의 배경 간단히 설명 → 입력 멘트 예시 제시해주기
- 조건(제한 사항, 출력 형식(리스트 형식vs연속문장 출력 형식, 글자수, 언어, 지식 수준, 말투, 성격))
- 예시
- step

```jsx
[1] 프롬프트 사용 목적:
(한 줄로 간단히)

[2] 사용자의 배경:
(간단한 소개 + 필요 시 예시 입력 멘트)

[3] 조건/제한 사항:
- 출력 형식:
- 글자 수:
- 언어:
- 지식 수준:
- 말투:
- 성격:
- 기타 조건:

[4] 예시:
- 입력 예시:
- 출력 예시:
```

최종 ver

```jsx
안녕하세요! AI가 당신의 의도에 맞게 잘 작동할 수 있도록 몇 가지 질문을 드릴게요.  
하나씩 대답해 주시면, 마지막에 바로 사용할 수 있는 완성 프롬프트를 만들어 드립니다.

[질문 1] 이번에 AI에게 어떤 작업을 시키고 싶으신가요? (한 줄로 작성)  
[질문 2] 간단한 자기 소개를 해주세요. (필요하다면, AI 입력 예시 문장도 함께 적어주세요.)
[질문 3] 답변을 어떤 형태로 받을까요? (리스트 / 연속 문장 / 표 / 코드 / 보고서)
[질문 4] 답변의 길이는 어느 정도로 할까요? (짧게 ~100자 / 보통 ~500자 / 길게 1000자 이상)
[질문 5] 답변은 어떤 언어로 받을까요? (한국어 / 영어 / 기타)
[질문 6] 답변의 난이도를 어느 수준에 맞출까요? (초등학생 / 고등학생 / 대학생 / 전문가)

-> AI가 참고할 예시 혹은 파일(pdf)가 있다면 추가해주세요. ''이건 작은 글씨로 넣어주세요!!''
```

질문에 대한 사용자 입력을 받아서 → 마스킹 → 다듬는 LLM(이건 2차때?)

프롬프트 생성 모델 **(마치 구현한 것처럼 …..)**

프롬프트 데이터

https://www.prpt.ai/prompt/list

https://pocket-prompt.com/prompt/text#google_vignette

→ 데이터셋 만들기 

- 좋은 프롬프트란?
    
    ### 좋은 프롬프트의 개선 유형 정의하기
    
    어떤 방향으로 프롬프트를 개선할지 구체적인 카테고리를 먼저 정의해야 합니다. 이는 데이터 생성의 기준점이 됩니다.
    
    - **① 명확성 및 구체성 추가:** 모호한 질문을 명확하게 만듭니다.
        - **(Bad)** `자동차에 대해 알려줘.`
        - **(Good)** `21세기 들어 발전한 전기 자동차의 역사에 대해 주요 기술적 혁신을 중심으로 설명해 줘.`
    - **② 맥락(Context) 제공:** 필요한 배경 정보를 추가합니다.
        - **(Bad)** `이 기사 요약해 줘.`
        - **(Good)** `[기사 본문 첨부] 이 인공지능 윤리 관련 기사를 요약해 줘. 특히 자율 살상 무기에 대한 저자의 핵심 반대 논거를 중심으로 정리해 줘.`
    - **③ 역할(Persona) 부여:** LLM에게 특정 전문가 역할을 부여합니다.
        - **(Bad)** `이메일 초안 써줘.`
        - **(Good)** `당신은 시니어 마케팅 매니저입니다. 잠재 고객에게 우리 회사의 신제품을 소개하는 전문적인 톤의 이메일 초안을 작성해 주세요.`
    - **④ 출력 형식 지정:** 원하는 결과물의 구조를 명시합니다.
        - **(Bad)** `광합성에 대해 설명해 줘.`
        - **(Good)** `광합성 과정을 세 문단으로 설명해 줘. 첫 문단은 간단한 개요, 두 번째 문단은 명반응, 세 번째 문단은 캘빈 회로에 대해 설명하고, 주요 투입물과 산출물은 글머리 기호로 목록을 만들어 줘.`
    - **⑤ 제약 조건 추가:** 원하지 않는 답변을 피하기 위한 조건을 추가합니다.
        - **(Bad)** `로봇이 나오는 소설을 써줘.`
        - **(Good)** `친절한 로봇에 대한 단편 소설을 써줘. 단, '미래'라는 단어는 사용하지 마.`

→ 모델선정

- mixtral 8x7B Instruct 모델
    
    Mixtral 8x7B Instruct는 프랑스의 AI 스타트업 미스트랄 AI(Mistral AI)가 개발한 고성능 오픈소스 언어 모델입니다. 이 모델의 가장 큰 특징은 이름에서도 알 수 있듯이 **'희소 전문가 혼합(Sparse Mixture of Experts, SMoE)'**이라는 혁신적인 아키텍처를 사용한다는 점입니다.
    
    쉽게 말해, 거대한 단일 모델 하나로 모든 문제를 해결하는 대신, **각기 다른 분야에 특화된 소규모 '전문가' 모델 여러 개를 두고, 주어진 질문에 가장 적합한 전문가 2명을 선택하여 협업시키는 방식**입니다.
    
    ---
    
    ### 핵심 개념: Mixture of Experts (MoE)
    
    기존의 언어 모델은 질문의 종류와 상관없이 항상 모델 전체를 사용해서 답변을 생성했습니다. 이는 마치 모든 과목을 한 명의 선생님이 가르치는 것과 같습니다.
    
    반면, Mixtral의 MoE 방식은 국어, 수학, 코딩 등 각 분야의 전문 선생님(Expert) 8명을 두고, 질문이 들어오면 어떤 선생님이 가장 잘 답변할지 판단하는 '라우터(Router)'가 해당 질문을 가장 잘 해결할 2명의 전문가에게 작업을 할당합니다. 그리고 두 전문가의 의견을 종합하여 최종 답변을 만듭니다.
    
    이 구조 덕분에 다음과 같은 장점이 생깁니다.
    
    1. **효율성 (Efficiency)**: 모델의 전체 파라미터(지식의 총량)는 467억 개(46.7B)에 달하지만, 실제로 하나의 토큰을 처리할 때는 선택된 2개의 전문가, 즉 약 129억 개(12.9B)의 파라미터만 사용합니다. 이로 인해 467억 개 파라미터를 가진 모델과 비슷한 성능을 내면서도 추론 속도는 훨씬 빠르고 비용은 저렴합니다.
    2. **성능 (Performance)**: 각 전문가가 특정 분야에 대해 더 깊이 학습할 수 있으므로, 단일 모델보다 더 높은 품질과 정확도를 보여줍니다. 특히 수학, 코딩, 다국어 처리와 같은 특정 분야에서 매우 뛰어난 성능을 발휘합니다.
    3. **확장성 (Scalability)**: 모델의 전체 파라미터 수를 늘리면서도 연산 비용을 효과적으로 제어할 수 있어, 모델을 더 크게 확장하기에 용이합니다.
    
    ---
    
    ### Mixtral 8x7B Instruct 모델의 주요 특징
    
    - **모델 구조**: 8개의 70억(7B) 파라미터 전문가 모델로 구성되어 '8x7B'라는 이름이 붙었습니다.
    - **성능 수준**: 여러 벤치마크에서 Llama 2 70B 모델을 능가하고, GPT-3.5와 비슷하거나 더 나은 성능을 보여주는 것으로 평가됩니다.
    - **컨텍스트 창**: 32,000 토큰의 긴 컨텍스트를 처리할 수 있어, 장문의 문서를 이해하고 요약하는 데 강점을 보입니다.
    - **다국어 지원**: 영어, 프랑스어, 이탈리아어, 독일어, 스페인어 등 다양한 언어를 능숙하게 처리합니다.
    - **코드 생성 능력**: 코드 생성 및 이해 능력이 뛰어나 개발자들에게 좋은 평가를 받고 있습니다.
    - **오픈소스**: Apache 2.0 라이선스로 공개되어 누구나 자유롭게 사용하고 수정하며 연구할 수 있습니다.
    - **Instruct 모델**: 'Instruct' 버전은 사용자의 지시사항(Instruction)을 잘 따르도록 미세조정(Fine-tuning)된 챗봇 형태의 모델로, 대화형 작업에 최적화되어 있습니다.
    
    결론적으로, Mixtral 8x7B Instruct는 **거대 모델의 높은 성능과 작은 모델의 효율성을 결합**한 혁신적인 모델로, 오픈소스 AI 생태계의 발전에 크게 기여한 것으로 평가받고 있습니다.
    
    ---
    

→ 학습

**접속 명령어:** ssh -p 9804 [bm_ai@210.94.179.19](mailto:bm_ai@210.94.179.19)
**pwd:** farmai002

팜 2번 서버입니당!!! → oss_team3에 있어요

```
가상환경 설정값

transformers==4.55.0
torch==2.8.0
❌ tensorflow not found
presidio-analyzer==2.2.359
presidio-anonymizer==2.2.359
numpy==2.2.6
protobuf==6.31.1
```

모델 실행 파일 경로
conda activate presidio-py310 #가상환경
cd oss_team3
cd presidio_custom
cd test
python code/local_only.py #마스킹 결과 출력 local2 -> local_only로 수정